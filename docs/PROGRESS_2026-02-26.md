# Echo Project Progress & Architecture Deep Dive (2026-02-26)

## TL;DR

This document captures all progress, architectural understanding, and strategic analysis from the Feb 25-26 development session. It serves as a complete context handoff for future sessions.

**Key accomplishments this session:**
1. Fixed all code review issues (race conditions, UUID instability, model normalization)
2. Added API Mode picker (client-direct vs backend-proxy) to iOS Settings UI
3. Fixed dark/light mode adaptive colors
4. Rewrote keyboard extension VoiceInputTrigger for reliability
5. Debugged Railway backend — confirmed fully operational
6. Implemented Volcano embedded encrypted API key system (AES-256-GCM)
7. Deep analysis of streaming pipeline, presets, and industry comparison

---

## 1. Repository & Build Info

- **Worktree**: `/Users/xianggui/.openclaw/workspace/Echo/.claude/worktrees/loving-ardinghelli`
- **Xcode Project**: `Echo.xcodeproj`
- **Bundle IDs**:
  - iOS: `com.xianggui.echo.app`
  - Keyboard: `com.xianggui.echo.app.keyboard`
  - macOS: `com.xianggui.echo.mac`
- **Railway Backend**: `https://echo-api-production-c83b.up.railway.app`
- **Physical Device**: iPhone 15 Pro Max (iPhone16,2), ID: `D66DE9A7-41BF-5F89-B1F4-B9B990912BC0`
- **WiFi Deploy Command**: `xcrun devicectl device install app --device D66DE9A7-41BF-5F89-B1F4-B9B990912BC0 /tmp/echo-build/Build/Products/Debug-iphoneos/EchoApp.app`
- **Build for device**: `xcodebuild build -project Echo.xcodeproj -scheme Echo -destination "generic/platform=iOS" -derivedDataPath /tmp/echo-build`
- **Tests**: 84/84 passing (`swift test --package-path Packages/EchoCore`)

---

## 2. Architecture Overview

### 2.1 Dual API Mode System

```
APICallMode enum:
  .clientDirect   → API keys stored locally in Keychain, direct provider connections
  .backendProxy   → Keys on Railway server, HTTP proxy through backend
```

**Provider Resolution Chain** (iOS `VoiceRecordingView.swift`, macOS `VoiceInputService.swift`):
```
resolveASRProvider()
  ├─ .clientDirect → asrProvider(for:) → direct provider with Keychain keys
  │     fallback → backend proxy → OpenAI fallback
  └─ .backendProxy → resolveCloudProxyProvider(for:) → BackendProxyASRProvider
        fallback → client-direct → OpenAI fallback
```

### 2.2 ASR Provider Matrix

| Provider | Streaming | Batch | Client-Direct | Backend-Proxy |
|----------|-----------|-------|---------------|---------------|
| **Volcano** | WebSocket (real-time) | Flash HTTP | Embedded key (new!) | Railway HTTP polling |
| **Deepgram** | WebSocket (real-time) | HTTP POST | Keychain key | Railway HTTP polling |
| **OpenAI Whisper** | N/A (batch only) | HTTP POST | Keychain key | Railway HTTP proxy |

### 2.3 Streaming Pipeline: Stream -> Finalize -> Polish

```
Recording Start
  ├─ [STREAMING] startStreaming() → AsyncStream<TranscriptionResult>
  │   feedAudio(chunk) → real-time partial results displayed
  │
  └─ [BATCH] collect all audio chunks silently

Recording Stop
  ├─ [STREAMING] stopStreaming() → final result
  │   Merge final + accumulated partials
  │   Check shouldFallbackToBatchFromStreaming() → batch retry if weak
  │
  └─ [BATCH] transcribe(audio) → full text result

Post-Processing
  ├─ [StreamFast ON] → Return text immediately → async polish in background
  │   Uses streamFastPolishOptions (lightweight: homophones + punctuation + dedup only)
  │   When done: autoReplace or confirmDiff review card
  │
  └─ [StreamFast OFF] → Full correction pipeline → wait → then display
      Uses settings.correctionOptions (full preset)
```

### 2.4 AutoEdit Presets (5 levels)

| Preset | Homophones | Punctuation | Formatting | Filler Removal | Dedup | Rewrite | Translation |
|--------|-----------|-------------|-----------|---------------|-------|---------|------------|
| **pureTranscript** | - | - | - | - | - | OFF | - |
| **streamFast** | Y | Y | - | - | Y | OFF | - |
| **smartPolish** (default) | Y | Y | Y | Y | Y | LIGHT | - |
| **deepEdit** | Y | Y | Y | Y | Y | STRONG | - |
| **custom** | user | user | user | user | user | user | user |

**Apply Modes**: `autoReplace` (auto-apply) or `confirmDiff` (show diff review card)

**Correction Providers**: Claude (claude-sonnet-4), OpenAI GPT (gpt-4o), Doubao, Qwen

**CorrectionOptions extras**:
- `rewriteIntensity`: .off / .light / .medium / .strong
- `structuredOutputStyle`: .off / .conciseParagraphs / .bulletList / .actionItems
- `translationTargetLanguage`: configurable

---

## 3. Changes Made This Session

### 3.1 Embedded Encrypted Key System (NEW)

**Problem**: Volcano Engine in client-direct mode required users to manually enter API keys. Backend-proxy mode only supports batch HTTP polling (no real WebSocket streaming), making Volcano slow.

**Solution**: AES-256-GCM encrypted Volcano API keys embedded directly in Swift code.

**Files created**:
- `Packages/EchoCore/Sources/EchoCore/Settings/EmbeddedKeyProvider.swift`
  - Decrypts embedded byte array at runtime
  - Seeds keys into Keychain (won't overwrite user-provided keys)
  - HKDF-SHA256 key derivation with fixed salt (`com.xianggui.echo`)
  - Works across all targets (iOS app, macOS app, keyboard extension)
- `scripts/embed_keys.swift`
  - Offline encryption tool matching the runtime derivation parameters
  - Usage: `swift scripts/embed_keys.swift --volcano-app-id "..." --volcano-access-key "..."`
- `Resources/EmbeddedKeys.enc` (intermediate artifact)

**Files modified**:
- `iOS/EchoApp/EchoApp.swift` — added `EmbeddedKeyProvider.shared.seedKeychainIfNeeded()` in init
- `macOS/EchoMac/App/AppDelegate.swift` — same in `applicationDidFinishLaunching`

**Flow**:
```
App starts → EmbeddedKeyProvider.seedKeychainIfNeeded()
  → Decrypt embedded byte array (AES-256-GCM)
  → Check Keychain for each key ID
  → If missing → write to Keychain
  → VolcanoASRProvider.resolveAppId() → finds key in Keychain
  → Client-direct WebSocket streaming works without user setup!
```

**Security**:
- Keys encrypted with AES-256-GCM, not plaintext in binary
- HKDF derivation uses compile-time master secret + fixed salt
- User-provided keys always take priority (seedKeychainIfNeeded checks hasKey first)
- iOS FairPlay DRM + code signing provide additional protection

**Re-encryption workflow** (when keys rotate):
```bash
swift scripts/embed_keys.swift \
  --volcano-app-id "NEW_ID" \
  --volcano-access-key "NEW_KEY" \
  --volcano-resource-id "volc.bigasr.auc_turbo" \
  --output Resources/EmbeddedKeys.enc
# Then convert .enc to hex bytes and update encryptedPayload in EmbeddedKeyProvider.swift
```

### 3.2 Railway Backend Investigation

**Railway Environment Variables** (verified via `railway variables`):
```
VOLCANO_APP_ID       = 6490217589
VOLCANO_ACCESS_KEY   = pYaGFt9q_xgejFQ-rZ9SVVa4hllXTamX
VOLCANO_RESOURCE_ID  = volc.bigasr.auc_turbo
VOLCANO_ENDPOINT     = (not set, defaults to flash batch endpoint)
DEEPGRAM_API_KEY     = 914bf23f203ae30fe69a1d50ec548a283a84458d
OPENAI_API_KEY       = sk-proj-1eo68Dk6...
JWT_SECRET           = recovery-please-rotate-this-secret
DATABASE_URL         = postgresql://postgres:...@postgres.railway.internal:5432/railway
```

**Key finding**: Railway backend's Volcano endpoint defaults to the **batch Flash API** (`/api/v3/auc/bigmodel/recognize/flash`), not the streaming WebSocket. This is why Volcano through backend proxy felt slow.

**BackendProxyASRProvider "streaming"** is actually HTTP polling every 0.75s — accumulates audio, base64 encodes, sends HTTP POST. Not real streaming.

### 3.3 API Mode Picker (Settings UI)

- Added `@State private var selectedAPIMode` with `.onChange` sync to `settings.apiCallMode`
- Shows contextual warnings:
  - "Sign in on Account tab first" if not authenticated
  - "Set Cloud API URL above" if URL empty
  - "Backend Proxy ready" with green checkmark when configured
- `APICallMode` gained `Identifiable` conformance for SwiftUI `ForEach`

### 3.4 Dark/Light Mode Fix

- `EchoMobileTheme` colors made dynamic using `UIColor { traits in ... }`
- `heroGradientStart`, `heroGradientEnd`, `accentSoft` all adapt to dark mode
- System colors used: `Color(.label)`, `Color(.systemBackground)`, `Color(.separator)`

### 3.5 Keyboard Extension Reliability

- `VoiceInputTrigger.swift` completely rewritten:
  - Simplified responder chain (performSelector instead of unsafeBitCast)
  - Increased timeout to 4.0s, poll interval 0.12s
  - Added `bridge.synchronize()` before polling
  - 0.3s initial delay for URL scheme propagation
  - Only clears launch intent when ALL URL candidates fail
- `KeyboardView.swift` — Full Access gate before attempting openMainApp

### 3.6 Code Review Fixes

- **C1 (iOS race)**: VoiceRecordingView recording task captures MainActor state inside `MainActor.run`
- **C2 (macOS race)**: VoiceInputService same pattern for `startAudioCollection`
- **M2 (UUID instability)**: MacAppSettings `currentUserId`/`localUserId` now persist on first read
- **M3 (model normalization)**: MacAppSettings added `normalizeOpenAIModel()` matching iOS pattern

---

## 4. Volcano Engine API Architecture

### Streaming (client-direct)
- **Protocol**: WebSocket binary frames (`wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_async`)
- **Resource ID**: `volc.bigasr.sauc.duration` (auto-mapped from batch resource IDs)
- **Auth**: Custom headers (`X-Api-App-Key`, `X-Api-Access-Key`, `X-Api-Resource-Id`)
- **Frame format**: 4-byte header + 4-byte payload size + payload (custom binary protocol)
- **Latency**: <100ms per frame

### Batch (Flash API)
- **Protocol**: HTTP POST (`https://openspeech.bytedance.com/api/v3/auc/bigmodel/recognize/flash`)
- **Resource ID**: `volc.bigasr.auc_turbo`
- **Auth**: Same custom headers
- **Payload**: JSON with base64-encoded complete audio
- **Latency**: 300-400ms for 5-second audio

### Resource ID Mapping (in VolcanoASRProvider)
```
Batch resources (.auc):          Streaming resources (.sauc):
volc.bigasr.auc_turbo        →   volc.bigasr.sauc.duration
volc.bigasr.auc.duration     →   volc.bigasr.sauc.duration
volc.bigasr.auc              →   volc.bigasr.sauc
```

---

## 5. Industry Comparison

### Echo vs Competitors

| Dimension | Echo | Doubao Input | Wispr Flow | SuperWhisper | Otter.ai |
|-----------|------|-------------|------------|-------------|---------|
| ASR Mode | Stream + Batch switchable | Stream (AcLLM) | Stream (chunked) | Batch only | Stream |
| Live Preview | Y (partial results) | Y (interim) | Y (partial) | N | Y |
| LLM Polish | 5 presets + 4 LLMs | Integrated in ASR | Fine-tuned Llama | GPT/Claude/Ollama | Post-meeting only |
| Async Polish | StreamFast deferred | N/A (LLM=ASR) | N | N | Post-recording |
| Diff Review | confirmDiff card | N | N | N | N |
| Multi-Provider | Volcano/Deepgram/OpenAI | Self only | Self only | Whisper/Deepgram | Self only |
| Backend Proxy | Railway dual-mode | N/A | N/A | N/A | Cloud |
| Polish Customization | 5 levels + custom + structured output | Fixed | Limited | Custom prompts | N |

### Echo's Core Differentiators

1. **Stream + Customizable Polish** (unique): No competitor does streaming + multi-level LLM polish with user review
2. **5-Tier Preset System** (unique): pureTranscript to deepEdit granularity
3. **confirmDiff Review Card** (unique): User approves/rejects LLM changes
4. **Multi-Provider Freedom**: 3 ASR x 4 LLM = 12 combinations
5. **Dual API Mode**: Client-direct (performance) or backend-proxy (security)

### Industry Best Practices (2024-2025)

**Standard 3-phase architecture**:
```
Phase 1: STREAM → audio chunks via WebSocket → interim results displayed
Phase 2: FINALIZE → silence/button triggers endpointing → stable final transcript
Phase 3: POLISH → LLM correction (grammar, filler, formatting) → 1-2s additional
```

**Two-pass rescoring** (academic frontier): CTC decoder (fast, streaming) + Attention decoder (accurate, at endpoint)

**Pipelining**: Start LLM before ASR fully finishes (Wispr Flow targets p99 <700ms)

**AcLLM architecture** (Doubao): LLM IS the ASR decoder, not a separate step. Eliminates one round trip. This is the frontier approach.

---

## 6. Strategic Recommendations

### Immediate (already implemented)
- [x] Volcano embedded encrypted key for client-direct streaming
- [x] API Mode picker in Settings UI
- [x] Railway env vars verified

### Near-term Improvements
- [ ] **VAD auto-sentence-break**: Auto-finalize during long continuous dictation (ref: Deepgram `speech_final`)
- [ ] **Pipeline parallelization**: Start LLM prefetch before ASR fully completes
- [ ] **Context injection for Polish**: Pass clipboard/active-app context to correction LLM (ref: SuperWhisper Super Mode)
- [ ] **Deepgram embedded key**: Same pattern as Volcano if wanting client-direct streaming for Deepgram

### Longer-term
- [ ] **Local Whisper fallback**: WhisperKit for offline ASR capability
- [ ] **Personalization**: Learn user writing style from correction history
- [ ] **WebSocket relay on Railway**: True streaming for backend-proxy mode (complex but would make all providers stream through backend)

---

## 7. Provider Decision Matrix (Current Recommendation)

| Provider | Recommended Mode | Reason |
|----------|-----------------|--------|
| **Volcano (streaming)** | Client-Direct (embedded key) | Real WebSocket streaming, <100ms latency |
| **OpenAI Whisper (batch)** | Backend-Proxy (Railway) | No streaming benefit; keep OpenAI key server-side |
| **Deepgram (streaming/batch)** | Backend-Proxy for now | Batch is fast enough; can add embedded key later for true streaming |

---

## 8. Key File Reference

### Core Settings
| File | Purpose |
|------|---------|
| `Packages/EchoCore/.../Settings/AppSettings.swift` | iOS app settings (preferStreaming, streamFastEnabled, correctionOptions, etc.) |
| `Packages/EchoCore/.../Settings/APICallMode.swift` | .clientDirect / .backendProxy enum |
| `Packages/EchoCore/.../Settings/EmbeddedKeyProvider.swift` | AES-GCM encrypted key decryption + Keychain seeding |
| `Packages/EchoCore/.../Settings/SecureKeyStore.swift` | Keychain wrapper with in-memory cache |
| `macOS/EchoMac/Services/MacAppSettings.swift` | macOS-specific settings (ASRMode, model normalization) |

### ASR Providers
| File | Purpose |
|------|---------|
| `Packages/EchoCore/.../ASR/ASRProvider.swift` | Protocol: transcribe, startStreaming, feedAudio, stopStreaming |
| `Packages/EchoCore/.../ASR/VolcanoASRProvider.swift` | Volcano batch (Flash) + streaming (WebSocket) |
| `Packages/EchoCore/.../ASR/VolcanoStreamingSession.swift` | Volcano binary WebSocket protocol implementation |
| `Packages/EchoCore/.../ASR/DeepgramASRProvider.swift` | Deepgram batch + streaming |
| `Packages/EchoCore/.../ASR/OpenAIWhisperProvider.swift` | OpenAI Whisper batch only |
| `Packages/EchoCore/.../ASR/BackendProxyASRProvider.swift` | HTTP polling proxy through Railway backend |

### LLM Correction
| File | Purpose |
|------|---------|
| `Packages/EchoCore/.../LLMCorrection/CorrectionOptions.swift` | AutoEditPreset enum, CorrectionOptions struct |
| `Packages/EchoCore/.../LLMCorrection/CorrectionPipeline.swift` | 3-stage: preDetect -> LLM correct -> verify |
| `Packages/EchoCore/.../LLMCorrection/ClaudeCorrectionProvider.swift` | Claude correction |
| `Packages/EchoCore/.../LLMCorrection/OpenAICorrectionProvider.swift` | GPT correction |

### Platform Integration
| File | Purpose |
|------|---------|
| `iOS/EchoApp/Views/VoiceRecordingView.swift` | iOS recording flow, streaming, finalize, polish |
| `iOS/EchoApp/Views/SettingsView.swift` | iOS settings UI (API mode picker, presets) |
| `iOS/EchoKeyboard/VoiceInputTrigger.swift` | Keyboard extension -> main app launch |
| `macOS/EchoMac/Services/VoiceInputService.swift` | macOS recording + provider resolution |
| `backend/src/index.ts` | Railway backend (auth, ASR proxy, sync) |
| `backend/src/config.ts` | Railway env var mapping |

### Scripts
| File | Purpose |
|------|---------|
| `scripts/embed_keys.swift` | Generate encrypted key payload for embedding |

---

## 9. Railway Backend Reference

**Endpoints**:
- `GET /healthz` → `{"ok":true}`
- `POST /v1/auth/register` → user registration
- `POST /v1/auth/login` → JWT token
- `POST /v1/asr/transcribe` → ASR proxy (requires Bearer token)
  - Supports: `openai_whisper`, `deepgram`, `volcano`
- `POST /v1/sync/upload` → cloud sync
- `GET /v1/billing/usage` → usage tracking

**ASR Proxy Flow**:
```
Client → POST /v1/asr/transcribe (Bearer token, base64 audio, provider ID)
  → Backend selects provider (OpenAI/Deepgram/Volcano)
  → Calls provider's batch API with server-side keys
  → Returns {text, language, provider, mode}
```

---

## 10. Deepgram Client-Direct vs Backend-Proxy Behavior Differences

Users reported observable differences between the two modes:

| Aspect | Client-Direct | Backend-Proxy |
|--------|--------------|---------------|
| Speed | Fast (WebSocket real-time) | Slower (0.75s HTTP polling) |
| Feel | "Direct translation" | "Delayed but more accurate" |
| Finalize | Deepgram native `is_final` message | Extra batch transcribe of full audio |
| Polish | No "second pass" feeling | Feels like "thinking/finalize" at end |
| Text duplication | None (each partial independent) | Yes (re-transcribes all accumulated audio each poll) |
| Accuracy | Stream-optimized | Potentially higher (full-context batch) |

**Root cause**: Backend proxy's `stopStreaming()` does a full batch `transcribe()` with all accumulated audio as a final step, which acts as a "second pass" that can be more accurate than streaming partials.

---

*Last updated: 2026-02-26*
*Session: loving-ardinghelli worktree*
